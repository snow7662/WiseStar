from pocketflow import Node, Flow, AsyncNode, AsyncParallelBatchFlow
from node_async import ReNode,PINode,AnswerNode
from utils.llm import call_llm_stream_async as call_llm_async
from utils.prompt_templates import REPI_DISTILL_NODE_PROMPT
from dotenv import load_dotenv
import asyncio
import json
import csv
import pandas as pd
import os

CONCURRENCY_LIMIT = os.getenv('CONCURRENCY_LIMIT')
CONCURRENCY_LIMIT = int(CONCURRENCY_LIMIT)

TIMEOUT = os.getenv('TIMEOUT')
TIMEOUT=int(TIMEOUT)

'''
è‡ªåŠ¨åŒ–æµ‹è¯•
åŠŸèƒ½ï¼šè°ƒç”¨agenté¡ºåºåšæ•°æ®é›†ä¸­çš„é¢˜ç›®ï¼Œå¹¶ä¸ç­”æ¡ˆè¿›è¡Œå¯¹æ¯”
è¾“å…¥ï¼šé¢˜ç›®æ•°æ®é›†ï¼ˆåŒ…å«idã€é¢˜ç›®ã€ç­”æ¡ˆï¼‰
è¾“å‡ºï¼šä¸€ä»½csvï¼Œåˆ—ä¸ºï¼šidã€agentç»™å‡ºçš„ç­”æ¡ˆanswerã€é¢˜ç›®ç­”æ¡ˆtruthã€å¯¹æ¯”ç»“æœfinal
åˆ‡æ¢æ•°æ®é›†è¯·ä¿®æ”¹ï¼šfilenameã€input_filepath
'''

'''
DistillNode---æå–èŠ‚ç‚¹
éœ€è¦ä½¿ç”¨çš„æ•°æ®: final_output
åŠŸèƒ½: ä»å®Œæ•´è§£é¢˜è¿‡ç¨‹final_outputä¸­æå–å‡ºæœ€ç»ˆç­”æ¡ˆ
'''

class DistillNode(AsyncNode):
    async def prep_async(self, shared):
        solve = shared.get('answer','none')
        return solve

    async def exec_async(self, prep_res):
        prompt = REPI_DISTILL_NODE_PROMPT.format(prep_res=prep_res)
        response = await call_llm_async(prompt)
        return response

    async def post_async(self, shared, prep_res, exec_res):
        shared['answer'] = exec_res

'''
EvaluationNode---æ¯”å¯¹èŠ‚ç‚¹
éœ€è¦ä½¿ç”¨çš„æ•°æ®: answer, truth
åŠŸèƒ½: å¯¹æ¯”æ¨¡å‹è¾“å‡ºçš„ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆçš„ä¸€è‡´æ€§
'''

class EvaluationNode(AsyncNode):
    async def prep_async(self, shared):
        # å‡†å¤‡è¯„ä¼°éœ€è¦çš„æ‰€æœ‰æ•°æ®
        return {
            "model_answer": shared.get("answer", "none"),
            "ground_truth": self.params.get("truth", "none")
        }

    async def exec_async(self, prep_res):
        model_answer = prep_res["model_answer"]
        ground_truth = prep_res["ground_truth"]

        # å¦‚æœä»»ä½•ä¸€ä¸ªç­”æ¡ˆæ— æ•ˆï¼Œç›´æ¥è¿”å›
        if model_answer == "none" or ground_truth == "none":
            return "Skipped - Missing Answer"

        eval_prompt = f'''
###ä»»åŠ¡
æ£€æµ‹ä¸¤ä¸ªç­”æ¡ˆæ˜¯å¦ä¸€è‡´

###å¾…æ£€æµ‹çš„ç­”æ¡ˆ
ç­”æ¡ˆ1: {model_answer}
ç­”æ¡ˆ2: {ground_truth}

###æ¡ˆä¾‹
-è¾“å…¥ï¼š sqrt(2)ã€æ ¹å·2
-è¾“å‡ºï¼š ä¸€è‡´

-è¾“å…¥ï¼šï¼ˆ1ï¼‰3 ï¼ˆ2ï¼‰ä¸ç›¸ç­‰ ã€ ç¬¬ä¸€å°é—®ï¼š3ï¼Œç¬¬äºŒå°é—®ï¼šæƒ³ç­‰
-è¾“å‡ºï¼šï¼ˆ1ï¼‰ä¸€è‡´ï¼Œ(2)ä¸ä¸€è‡´

-è¾“å…¥ï¼šC.çº¿æ®µADçš„é•¿åº¦ä¸º12  ã€  C
-è¾“å‡ºï¼šä¸€è‡´

###æ³¨æ„äº‹é¡¹
ä½ çš„è¾“å‡ºåªèƒ½ä¸ºâ€œä¸€è‡´â€æˆ–â€œä¸ä¸€è‡´â€ï¼ˆå¯ä»¥åŒ…å«å°é—®çš„ä¸€è‡´ã€ä¸ä¸€è‡´ï¼‰ï¼Œä¸åŒ…å«å¤šä½™çš„è§£é‡Š
'''

        return await call_llm_async(eval_prompt)

    async def post_async(self, shared, prep_res, exec_res):
        # å°†è¯„ä¼°ç»“æœå­˜å…¥shared
        shared['final_result'] = exec_res

'''
SaveResultNode---ä¿å­˜èŠ‚ç‚¹
åŠŸèƒ½: ä¿å­˜å¼‚æ­¥æ‰¹å¤„ç†æµä¸­å•ä¸ªä»»åŠ¡çš„ç»“æœ
'''

class SaveResultNode(Node):
    """
    è¿™ä¸ªèŠ‚ç‚¹æ˜¯åŒæ­¥çš„ï¼Œè´Ÿè´£å°†å•ä¸ªä»»åŠ¡çš„ç»“æœå®‰å…¨åœ°å†™å…¥CSVæ–‡ä»¶ã€‚
    å®ƒåœ¨æ¯ä¸ªå¹¶è¡Œæµç¨‹çš„æœ€åè¢«è°ƒç”¨ã€‚
    """

    def prep(self, shared):
        # ä» shared ä¸­å‡†å¤‡å¥½è¦å†™å…¥ä¸€è¡Œçš„æ•°æ®
        # é€šè¿‡ self.params è·å–ç”± Flow ä¼ é€’è¿‡æ¥çš„å…¨å±€å‚æ•°
        return {
            "output_filename": self.params.get("output_filename"),
            "row_data": [
                self.params.get("id", "N/A"),
                self.params.get("question", "N/A"),
                shared.get("answer", "ERROR"),
                self.params.get("truth", "N/A"),
                shared.get("final_result", "EVAL_ERROR")
            ]
        }

    def exec(self, prep_res):
        filename = prep_res["output_filename"]
        row = prep_res["row_data"]

        # ä½¿ç”¨'a'æ¨¡å¼è¿½åŠ å†™å…¥
        with open(filename, 'a', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(row)

        # åœ¨æ§åˆ¶å°æ‰“å°ä¿å­˜ç¡®è®¤ä¿¡æ¯ï¼Œä¾¿äºè¿½è¸ªè¿›åº¦
        print(f"âœ… [SaveResultNode] ID: {row[0]} - ç»“æœå·²ä¿å­˜ã€‚")
        return "saved"


class TestAutomationFlow(AsyncParallelBatchFlow):
    """
    ä¸€ä¸ªå¥å£®çš„å¼‚æ­¥å¹¶è¡Œæ‰¹å¤„ç†æµç¨‹ï¼Œç”¨äºè‡ªåŠ¨åŒ–æµ‹è¯•Agentã€‚
    æ ¸å¿ƒç‰¹æ€§ï¼š
    1.  **çŠ¶æ€éš”ç¦»**: æ¯ä¸ªå¹¶è¡Œä»»åŠ¡éƒ½æœ‰å…¶ç‹¬ç«‹çš„`shared`çŠ¶æ€ï¼Œé˜²æ­¢æ•°æ®äº¤å‰æ±¡æŸ“ã€‚
    2.  **å¹¶å‘æ§åˆ¶**: ä½¿ç”¨Semaphoreé™åˆ¶åŒæ—¶è¿è¡Œçš„ä»»åŠ¡æ•°é‡ï¼Œé¿å…APIè¿‡è½½ã€‚
    3.  **æ–­ç‚¹ç»­ä¼ **: è‡ªåŠ¨è·³è¿‡è¾“å‡ºæ–‡ä»¶ä¸­å·²å­˜åœ¨çš„IDï¼Œå¯ä»¥éšæ—¶ä¸­æ–­å’Œæ¢å¤ã€‚
    """

    def __init__(self, start_node, input_filepath, output_filename, concurrency_limit=CONCURRENCY_LIMIT):
        super().__init__(start=start_node)
        self.input_filepath = input_filepath
        self.output_filename = output_filename
        # è®¾ç½®å…¨å±€å‚æ•°ï¼Œä¾›æ‰€æœ‰å­ä»»åŠ¡ä¸­çš„èŠ‚ç‚¹ï¼ˆå¦‚SaveResultNodeï¼‰è®¿é—®
        self.set_params({"output_filename": self.output_filename})
        # åˆ›å»ºä¸€ä¸ªSemaphoreå®ä¾‹ç”¨äºå¹¶å‘æ§åˆ¶
        self.semaphore = asyncio.Semaphore(concurrency_limit)
        print(f"ğŸš¦ å¹¶å‘æ§åˆ¶å™¨å·²å¯åŠ¨ï¼Œé™åˆ¶ä¸º {concurrency_limit} ä¸ªå¹¶è¡Œä»»åŠ¡ã€‚")

    async def prep_async(self, shared):
        """
        åœ¨æµç¨‹å¼€å§‹å‰è¿è¡Œï¼Œè´Ÿè´£åŠ è½½æ‰€æœ‰ä»»åŠ¡å¹¶æ ¹æ®è¾“å‡ºæ–‡ä»¶è¿‡æ»¤æ‰å·²å®Œæˆçš„ä»»åŠ¡ã€‚
        """
        print("ğŸš€ [Flow Prep] å¼€å§‹åŠ è½½æ•°æ®å¹¶è¿‡æ»¤å·²å¤„ç†é¡¹...")
        processed_ids = set()
        if os.path.exists(self.output_filename):
            try:
                # ä½¿ç”¨pandasè¯»å–æ›´å¥å£®ï¼Œèƒ½å¤„ç†ç©ºæ–‡ä»¶ç­‰æƒ…å†µ
                df = pd.read_csv(self.output_filename, dtype={'id': str})
                if 'id' in df.columns:
                    processed_ids = set(df['id'].dropna())
                print(f"ğŸ” å·²æ‰¾åˆ° {len(processed_ids)} ä¸ªå·²å¤„ç†çš„IDã€‚")
            except pd.errors.EmptyDataError:
                print(f"ğŸ“‹ è¾“å‡ºæ–‡ä»¶ '{self.output_filename}' ä¸ºç©ºï¼Œå°†å¤„ç†æ‰€æœ‰ä»»åŠ¡ã€‚")
            except Exception as e:
                print(f"âš ï¸ è¯»å–ç°æœ‰CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}ï¼Œå°†å¤„ç†æ‰€æœ‰ä»»åŠ¡ã€‚")

        try:
            with open(self.input_filepath, 'r', encoding='utf-8') as f:
                datasets = json.load(f)
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®é›† '{self.input_filepath}' å¤±è´¥: {e}")
            return []  # è¿”å›ç©ºåˆ—è¡¨ä»¥åœæ­¢æµç¨‹

        # å‡†å¤‡è¦å¹¶è¡Œå¤„ç†çš„ä»»åŠ¡å‚æ•°åˆ—è¡¨
        tasks_to_run = []
        for data in datasets:
            current_id = str(data.get("id"))
            if current_id not in processed_ids:
                tasks_to_run.append({
                    "id": current_id,
                    "question": data.get("questionï¼ˆçº¯æ–‡æœ¬ï¼‰", "N/A"),
                    "truth": data.get('ground_truth', "N/A")
                })

        print(f"âš¡ï¸ å‡†å¤‡äº† {len(tasks_to_run)} ä¸ªæ–°ä»»åŠ¡è¿›è¡Œå¹¶è¡Œå¤„ç†ã€‚")
        return tasks_to_run  # è¿”å›ä»»åŠ¡å‚æ•°åˆ—è¡¨

    async def _orch_async(self, shared, params=None):
        """
        é‡å†™çš„æ ¸å¿ƒç¼–æ’å™¨ï¼Œæ¥æ”¶ä¸€ä¸ªç‹¬ç«‹çš„sharedå­—å…¸å’Œä»»åŠ¡å‚æ•°ã€‚
        """
        # å°†ä»»åŠ¡ç‰¹æœ‰çš„å‚æ•°ï¼ˆå¦‚id, questionï¼‰æ³¨å…¥åˆ°è¿™ä¸ªä»»åŠ¡ç§æœ‰çš„sharedçŠ¶æ€ä¸­
        if params:
            shared.update(params)

        curr = self.start_node
        last_action = None

        # flowçš„å…¨å±€å‚æ•°ï¼ˆå¦‚output_filenameï¼‰é€šè¿‡pä¼ é€’
        p = self.params.copy()
        if params:
            p.update(params)

        while curr:
            curr.set_params(p)
            if isinstance(curr, AsyncNode):
                last_action = await curr._run_async(shared)
            else:
                last_action = curr._run(shared)
            curr = self.get_next_node(curr, last_action)
        return last_action

    async def _run_task_with_semaphore(self, task_params):
        """
        ä¸€ä¸ªåŒ…è£…å™¨ï¼Œä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºç‹¬ç«‹çš„sharedå­—å…¸ï¼Œå¹¶ä½¿ç”¨semaphoreè¿›è¡Œå¹¶å‘æ§åˆ¶ã€‚
        """
        async with self.semaphore:
            # å…³é”®ï¼šä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„ã€å¹²å‡€çš„ shared å­—å…¸
            # task_params åŒ…å«äº† id, question, truth ç­‰ä¿¡æ¯
            return await self._orch_async({}, {**self.params, **task_params})

    async def _run_async(self, shared):
        """
        æµç¨‹çš„å…¥å£ã€‚å®ƒè·å–ä»»åŠ¡åˆ—è¡¨ï¼Œå¹¶ä¸ºæ¯ä¸ªä»»åŠ¡å¯åŠ¨ä¸€ä¸ªå¸¦çŠ¶æ€éš”ç¦»å’Œå¹¶å‘æ§åˆ¶çš„æµç¨‹ã€‚
        """
        tasks_params_list = await self.prep_async(shared) or []

        # ä½¿ç”¨ asyncio.gather å¹¶å‘è¿è¡Œæ‰€æœ‰åŒ…è£…åçš„ä»»åŠ¡
        await asyncio.gather(*(self._run_task_with_semaphore(params) for params in tasks_params_list))

        return await self.post_async(shared, tasks_params_list, None)


def create_async_test_flow(input_path, output_path):
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºå¹¶é…ç½®è‡ªåŠ¨æµ‹è¯•çš„å®Œæ•´å·¥ä½œæµã€‚
    """
    # 1. å®ä¾‹åŒ–æ‰€æœ‰éœ€è¦çš„èŠ‚ç‚¹
    re_node = ReNode()
    # åœ¨è¿™é‡Œä¸ºPINodeè®¾ç½®è¶…æ—¶æ—¶é—´
    pi_node = PINode(timeout_seconds=TIMEOUT)
    distill_node = DistillNode()
    evaluation_node = EvaluationNode()
    saver_node = SaveResultNode()

    # 2. ç¼–æ’èŠ‚ç‚¹æµç¨‹ (ä¿æŒä¸å˜)
    re_node - "calculate" >> pi_node
    pi_node - "feedback" >> re_node
    re_node - "answer" >> distill_node
    distill_node >> evaluation_node >> saver_node

    # 3. åˆ›å»ºå¹¶è¿”å›é…ç½®å¥½çš„ Flow å®ä¾‹
    return TestAutomationFlow(
        start_node=re_node,
        input_filepath=input_path,
        output_filename=output_path,
        concurrency_limit=CONCURRENCY_LIMIT
    )

def sort_csv_by_id(file_path: str) -> None:
    """
    è¯»å–æŒ‡å®š CSV æ–‡ä»¶ï¼ŒæŒ‰ id å‡åºæ’åºï¼ŒåŒæ—¶è¿‡æ»¤ç©ºè¡Œå’Œå­—æ®µä¸å®Œæ•´çš„è¡Œã€‚

    :param file_path: CSV æ–‡ä»¶è·¯å¾„
    """
    if not os.path.exists(file_path):
        print(f"âš ï¸ æ–‡ä»¶ '{file_path}' ä¸å­˜åœ¨ï¼Œè·³è¿‡æ’åºã€‚")
        return

    print(f"ğŸ”„ æ­£åœ¨å¯¹ '{file_path}' æŒ‰ id æ’åº...")

    try:
        with open(file_path, 'r', encoding='utf-8-sig', newline='') as f:
            reader = csv.reader(f)
            header = next(reader)  # è¯»å–è¡¨å¤´
            rows = list(reader)    # è¯»å–æ‰€æœ‰æ•°æ®è¡Œ

        # è¿‡æ»¤ç©ºè¡Œå’Œå­—æ®µä¸è¶³çš„è¡Œ
        valid_rows = []
        empty_rows_count = 0
        invalid_rows_count = 0

        for row in rows:
            if not row:  # ç©ºè¡Œï¼ˆå¦‚è¯»å–åˆ°ç©ºåˆ—è¡¨[]ï¼‰
                empty_rows_count += 1
            elif len(row) < 5:  # å­—æ®µä¸è¶³
                invalid_rows_count += 1
            else:
                valid_rows.append(row)

        # è¾“å‡ºè¿‡æ»¤ä¿¡æ¯
        if empty_rows_count > 0:
            print(f"âš ï¸ æ£€æµ‹åˆ°å¹¶åˆ é™¤äº† {empty_rows_count} è¡Œç©ºè¡Œã€‚")
        if invalid_rows_count > 0:
            print(f"âš ï¸ æ£€æµ‹åˆ°å¹¶åˆ é™¤äº† {invalid_rows_count} è¡Œå­—æ®µä¸å®Œæ•´çš„æ•°æ®ã€‚")

        # æŒ‰ id æ’åº
        valid_rows.sort(key=lambda x: int(x[0]))

        # è¦†ç›–å†™å…¥åŸæ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(header)  # å†™å…¥è¡¨å¤´
            writer.writerows(valid_rows)  # å†™å…¥æ’åºåçš„æœ‰æ•ˆè¡Œ

        print(f"âœ… å·²æˆåŠŸæŒ‰ id æ’åºå¹¶ä¿å­˜è‡³ '{file_path}'")

    except Exception as e:
        print(f"âŒ æ’åºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{e}")

# --- æ­¥éª¤ 4: é‡æ„ä¸»ç¨‹åºä»¥è°ƒç”¨å¼‚æ­¥æµç¨‹ ---

async def main():
    """ä¸»å¼‚æ­¥å‡½æ•°ï¼Œè´Ÿè´£è®¾ç½®å’Œå¯åŠ¨æµç¨‹"""
    # åˆå§‹åŒ–æ–‡ä»¶å
    load_dotenv()
    filename = os.getenv("FILE_NAME")
    modelname = os.getenv(("MODEL_NAME"))
    input_filepath = f'../../../data/{filename}.json'
    output_filename = f'../../../output_data/{filename}_RePI_{modelname}_å¯¹æ¯”ç»“æœ.csv'

    # æ£€æŸ¥å¹¶å†™å…¥CSVè¡¨å¤´ï¼ˆå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼‰
    # è¿™æ˜¯ä¸€ä¸ªä¸€æ¬¡æ€§çš„è®¾ç½®æ“ä½œï¼Œåœ¨æ‰€æœ‰å¹¶è¡Œä»»åŠ¡å¼€å§‹å‰å®Œæˆ
    if not os.path.exists(output_filename):
        print(f"ğŸ“‹ è¾“å‡ºæ–‡ä»¶ '{output_filename}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»ºå¹¶å†™å…¥è¡¨å¤´...")
        with open(output_filename, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['id', 'problem', 'answer', 'truth', 'final'])

    # åˆ›å»ºå¼‚æ­¥æµç¨‹å®ä¾‹
    test_flow = create_async_test_flow(input_filepath, output_filename)

    print("\n--- ğŸš€ å¼€å§‹å¼‚æ­¥å¹¶è¡Œæ‰¹å¤„ç† ---")
    # ä½¿ç”¨ run_async å¯åŠ¨æ•´ä¸ªæµç¨‹ï¼Œåˆå§‹sharedä¸ºç©º
    # Flowçš„prep_asyncä¼šè´Ÿè´£åŠ è½½æ‰€æœ‰æ•°æ®
    await test_flow.run_async({})
    print("\n--- âœ… å¼‚æ­¥å¹¶è¡Œæ‰¹å¤„ç†å®Œæˆ ---")

    sort_csv_by_id(output_filename)

if __name__ == '__main__':
    # ä½¿ç”¨ asyncio.run æ¥æ‰§è¡Œé¡¶å±‚çš„å¼‚æ­¥ä¸»å‡½æ•°
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­äº†ç¨‹åºã€‚")